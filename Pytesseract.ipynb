{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b3c4234c",
      "metadata": {
        "id": "b3c4234c"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "027493cc",
      "metadata": {
        "collapsed": true,
        "id": "027493cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "509eec51-1d46-4986-e9c4-0588cb869fd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.4.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.6.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.21.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.64.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.1.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (21.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.9.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.3)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (8.1.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.4.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [901 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,527 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,306 kB]\n",
            "Hit:14 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,905 kB]\n",
            "Get:16 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.9 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,336 kB]\n",
            "Get:19 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [87.8 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,068 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,109 kB]\n",
            "Hit:23 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,076 kB]\n",
            "Get:25 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,063 kB]\n",
            "Get:26 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Fetched 16.8 MB in 4s (3,805 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "76 packages can be upgraded. Run 'apt list --upgradable' to see them.\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow\n",
        "!pip install spacy\n",
        "!sudo apt update"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!apt-get install poppler-utils\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIK0r2jMNotK",
        "outputId": "c3377394-0b1c-4d34-c681-b927341e88aa"
      },
      "id": "UIK0r2jMNotK",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.9)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (9.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.7/dist-packages (from pytesseract) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=21.3->pytesseract) (3.0.9)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (0.62.0-2ubuntu2.12).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libtesseract-dev is already the newest version (4.00~git2288-10f4998a-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 76 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Restart Runtime After Installation"
      ],
      "metadata": {
        "id": "-iCqt_hgBo5D"
      },
      "id": "-iCqt_hgBo5D"
    },
    {
      "cell_type": "markdown",
      "id": "1881b845",
      "metadata": {
        "id": "1881b845"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4426083",
      "metadata": {
        "id": "c4426083"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "050e86a4",
      "metadata": {
        "id": "050e86a4"
      },
      "source": [
        "# Downloading Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc6fcf7f",
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc6fcf7f",
        "outputId": "cf2eff78-a86f-4848-a814-e45e89f64735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-04 11:25:37.672971: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 6.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d19b21d1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d19b21d1",
        "outputId": "4e238719-dde9-4695-b80e-97885c0aca2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive"
      ],
      "metadata": {
        "id": "_bkGRDFGB4Sa"
      },
      "id": "_bkGRDFGB4Sa"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CIYUFICaPQ-",
        "outputId": "bfbc3e78-9e0c-4efc-f4ba-a0560900c062"
      },
      "id": "-CIYUFICaPQ-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "788d7abb",
      "metadata": {
        "id": "788d7abb"
      },
      "source": [
        "# Pre Processing Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27d0910b",
      "metadata": {
        "id": "27d0910b"
      },
      "outputs": [],
      "source": [
        "def ZoomImage(img, zoom_factor=2):\n",
        "    return cv2.resize(img, None, fx= zoom_factor, fy= zoom_factor, interpolation= cv2.INTER_LINEAR)\n",
        "\n",
        "def GrayScaleImage(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = 255*(gray < 128).astype(np.uint8) \n",
        "    return gray\n",
        "\n",
        "def InvertImage(img):\n",
        "    return cv2.bitwise_not(img)\n",
        "\n",
        "def CropImage(img):\n",
        "    # Find all non-zero points (text)\n",
        "    coords = cv2.findNonZero(img) \n",
        "    # Find minimum spanning bounding box\n",
        "    x, y, w, h = cv2.boundingRect(coords) \n",
        "    # Crop the image - note we do this on the original image\n",
        "    img = img[y:y+h, x:x+w] \n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0583535",
      "metadata": {
        "id": "b0583535"
      },
      "source": [
        "# Creating Bounding Box In Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c37bd914",
      "metadata": {
        "id": "c37bd914"
      },
      "outputs": [],
      "source": [
        "def CreateBoundingBox(img):\n",
        "    h, w, c = img.shape\n",
        "    boxes = pytesseract.image_to_boxes(img) \n",
        "    for b in boxes.splitlines():\n",
        "        b = b.split(' ')\n",
        "        img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff9ff256",
      "metadata": {
        "id": "ff9ff256"
      },
      "source": [
        "# Extracting Text From Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "958fe4fd",
      "metadata": {
        "id": "958fe4fd"
      },
      "outputs": [],
      "source": [
        "def ExtractText(img) : \n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    text = pytesseract.image_to_string(img, config=custom_config)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffb2a5c6",
      "metadata": {
        "id": "ffb2a5c6"
      },
      "source": [
        "# Extracting Name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre Processing For Name"
      ],
      "metadata": {
        "id": "8qqPGeKMxKgO"
      },
      "id": "8qqPGeKMxKgO"
    },
    {
      "cell_type": "code",
      "source": [
        "def text_preprocessing(text):\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "  newSentence = \"\"\n",
        "  for word in text:\n",
        "      if (word in punctuations):\n",
        "          newSentence = newSentence + \" \"\n",
        "      else: \n",
        "          newSentence = newSentence + word\n",
        "\n",
        "  return newSentence\n",
        "\n",
        "def remove_white_spaces(text):\n",
        "  token_words = word_tokenize(text)\n",
        "  new_sentence = []\n",
        "  for word in token_words:\n",
        "    new_sentence.append(word) \n",
        "    new_sentence.append(\" \") \n",
        "  return \"\".join(new_sentence)\n",
        "\n",
        "def removing_extra(text):\n",
        "  new_sentence = \"\"\n",
        "  result = \"\"\n",
        "  token_sentence = sent_tokenize(text)\n",
        "  if \"applying for\" in token_sentence[0].lower() or \"applied for\" in token_sentence[0].lower() or \"post applied\" in token_sentence[0].lower():\n",
        "    sentences = token_sentence[0].split(\"\\n\")\n",
        "    for sent in sentences:\n",
        "      if \"applying for\" in sent.lower() or \"applied for\" in sent.lower():\n",
        "        continue\n",
        "      else:\n",
        "        new_sentence = new_sentence + sent + \"\\n\"\n",
        "\n",
        "    i = 0\n",
        "    for sentence in token_sentence:\n",
        "      if i == 0:\n",
        "        result = result + new_sentence + \"\\n\"\n",
        "      else:\n",
        "        result = result + sentence  + \"\\n\"\n",
        "      i += 1\n",
        "    return result \n",
        "  else:\n",
        "    return text"
      ],
      "metadata": {
        "id": "rgfz0pIaop7A"
      },
      "id": "rgfz0pIaop7A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# from spacy.matcher import Matcher\n",
        "\n",
        "# nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# #words to be avoided in extraction\n",
        "# avoid_words = ['resume','résumé','cv', 'curriculum','marketing', 'curriculum vitae','vitae', 'curriculum vita',\n",
        "#                  'vita', 'name', 'pg', 'india', 'curriculam vitae', 'business development', 'cast', 'coc,','uae',\n",
        "#                  'address', 'email', 'email address', 'sales', 'u.p', 'product development', 'personal statement',\n",
        "#                  'full Name','street address', 'mobile', 'phone', 'number', 'phone number', 'mobile number', 'product',\n",
        "#                  'agarwal', 'inter', 'secondary', 'steels', 'element', 'engineering','system', 'school', 'operating',\n",
        "#                  'acknowledgement', 'assimilated', 'collaborated', 'collaboration','collaborations', 'india', 'isf,',\n",
        "#                  'professional summary', 'professional', 'title', 'job title', 'job' 'technological', 'high', 'college',\n",
        "#                  'top', 'device', 'launch', 'ams', 'crm', 'P Technological', 'project engineer', 'cgpa', 'gpa',\n",
        "#                  'personal profile', 'years', 'lv', 'career', 'career profile','lv', 'curriculum viate', 'civil',\n",
        "#                  'post applied', 'applied', 'post', 'for', 'electrical engineer', 'ps', 'district', 'ilets',\n",
        "#                  'career objective.', 'it', 'carrier objective', 'electrical project handling', 'mig,', 'hvac',\n",
        "#                  'mdu', 'linkedin', 'facebook', 'behance', 'youtube', 'github', 'in', 'portfolio','total experience',\n",
        "#                  'pbd','working','xcx','wwd','mba','dtdc','cf ril', 'fi', 'ef', 'dd', 'project management',\n",
        "#                  'engineer', 'apj', 'course university', 'university', 'ltd.', 'educational', 'n.y.', 's.s.',\n",
        "#                  'information technology', 'uk', 'usa', 'uae','pakistan','china','canada','saudia','arabia',\n",
        "#                  'educational background', 'details', 'personal details', 'clout', 'cloud', 'inditex', 'vy.', 'instrument',\n",
        "#                  'instrument super', 'bca', 'u.p.', 'qa', 'gis', 'gre', 'aicte', 'professional and', 'education background',\n",
        "#                  'tx', 'pvc', 'acadmic qualification', 'apply for merchandiser', 'education background','bechelor',\n",
        "#                  'beardsell pvt.', 'class', 'fi ef', 'uae,', 'of', 'b.s.', 'project', 'applied for','applying for',\n",
        "#                  'contributed', 'participated', 'participations', 'partnered', 'partnerships', 'volunteer work',\n",
        "#                  'volunteer', 'side activities', 'projects', 'education', 'experience', 'work', 'work experience',\n",
        "#                  'skills', 'interests', 'biography', 'bio', 'about me', 'about', 'info', 'contact', 'contact info',\n",
        "#                  'reference', 'reference will be established upon request', 'certificates', 'additional certificates',\n",
        "#                  'courses', 'student', 'online courses', 'short courses', 'languages', 'internships', 'organizations',\n",
        "#                  'organization', 'matriculation', 'intermediate', 'pre-engineering', 'bachelors', 'masters',\n",
        "#                  'bscs', 'bachelor of science', 'btech', 'btech', 'bachelor of technology', 'bs-cs,', 'sslc',\n",
        "#                  'bse', 'bachelor of commerce', 'bcom', 'b.com', 'information', 'personal information', 'curriculam',\n",
        "#                  'info','achievements', 'personal projects', 'personal skills', 'summary', 'courses and certificates:',\n",
        "#                  'profile', 'hobbies & interests', 'hobbies and interests', 'hobbies', 'career objective',\n",
        "#                  'objective', 'other skills', 'academic', 'academics', 'academic qualification', 'references', 'viate',\n",
        "#                  'personal', 'cnic', 'dob', 'date of birth', 'work history','computer skills', 'referenc', 'mechanical',\n",
        "#                  'economics and finance', 'top skills', 'personal email', 'contact no', 'contact no.', 'electrical',\n",
        "#                  'cnic no', 'cnic no.', 'religion', 'domicile', 'a levels', 'o levels', 'working links', 'e mail',\n",
        "#                  'links', 'working experience', 'awards and achievements', 'awards', 'soft skills', 'diploma holder',\n",
        "#                  'volunteer experience', 'conferences and courses', 'conferences', 'educational qualification',\n",
        "#                  'educational qualifications', 'value addition', 'declaration', 'brief employment history',\n",
        "#                  'extra activities', 'extra', 'skills and responsibilities', 'duties and responsibilities',\n",
        "#                  'skills and abilities', 'area of expertise', 'technical skills', 'current address', 'street',\n",
        "#                  'permanent address', 'passport no', 'expiry date', 'career summary', 'email id', 'phone no',\n",
        "#                  'contact no', 'contact no.', 'phone no.', 'education qualification', 'python', 'js6', 'ansys',\n",
        "#                  'critical', 'conditions', 'handling', 'a', 'b', 'c', 'd', 'e', 'f','g','h','i','j','k','l','m',\n",
        "#                  'n','o','p','q','r','s','t','u','v','w','x','y','z'\n",
        "#                  ]\n",
        "\n",
        "# #creating an instance of matcher for real words with nlp.vocab\n",
        "# matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# #extracts names\n",
        "# def extract_name(content):\n",
        "\n",
        "#     #pre-processing to remove any faulty punctuation\n",
        "#     new_content = text_preprocessing(content)\n",
        "    \n",
        "#     #data annotation\n",
        "#     nlp_text = nlp(new_content)\n",
        "    \n",
        "#     #patterns for names\n",
        "#     patterns = [\n",
        "#                [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}],\n",
        "#                [{'POS': 'PROPN'}, {'POS': 'PROPN'}, {'POS': 'PROPN'}],\n",
        "#                [{'POS': 'PROPN'}, {'POS': 'PROPN'}],\n",
        "#                [{'POS': 'PROPN'}]\n",
        "#                ]\n",
        "\n",
        "#     #checking the best match name and pulling it out\n",
        "#     results = []\n",
        "#     for pattern in patterns:\n",
        "#       matcher.add('NAME', [pattern])\n",
        "\n",
        "#       matches = matcher(nlp_text)\n",
        "\n",
        "#       for match_id, start, end in matches:\n",
        "#           span = nlp_text[start:end]\n",
        "#           if not span.text.lower() in avoid_words:\n",
        "#             results.append(span.text)\n",
        "#             break\n",
        "    \n",
        "#     for result in results:\n",
        "#       if (not any(element in avoid_words for element in result.split(' ')) ) and len(result)>1:\n",
        "#         return result\n",
        "          \n",
        "#     return \"\""
      ],
      "metadata": {
        "id": "OBWMGgiYRgvn"
      },
      "id": "OBWMGgiYRgvn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bc1267d1",
      "metadata": {
        "id": "bc1267d1"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import words\n",
        "\n",
        "def extract_name_using_Pronoun(content):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    ignore_words = [\"curriculum\" , \"vitae\" , \"vita\" , \"post\" , \"applied\" , \"for\" , \"address\" , \"resume\" , \"engineering\" , \"engineer\",\n",
        "                \"mechanical\" , \"address\" , \"mobile\" , \"contact\" , \"phone\" , \"temporary\" , \"street\" , \"resume\", \"computer\" ,\n",
        "                \"software\" , \"personal\" , \"information\" , \"name\" , \"date\" , \"box\" , \"work\" , \"professional\", \"near\" ,\n",
        "                \"objective\" , \"general\" , \"skills\" , \"skill\" , \"officer\" , \"administration\" , \"administrator\" , \"career\", \"position\",\n",
        "                \"technology\" , \"IT\", \"qualification\" , \"academic\", \"experience\", \"department\" , \"email\" , \"e-mail\" , \"curriculam\", \n",
        "                \"viate\" , \"education\" , \"location\"]\n",
        "\n",
        "    new_content = removing_extra(content)\n",
        "    # new_content = text_preprocessing(new_content)\n",
        "    nlp_text = nlp(new_content)\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>/?@#$%^&*_~'''\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', [pattern])\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        foundwords = span.text.lower().split()\n",
        "        found = 0\n",
        "        for word in foundwords:\n",
        "          if word in ignore_words:\n",
        "            found = 1\n",
        "            break\n",
        "        if not(found):\n",
        "          token_words = word_tokenize(span.text)\n",
        "          flag = 0\n",
        "          for word in token_words:\n",
        "            if word in punctuations:\n",
        "              flag = 1 \n",
        "              break\n",
        "          if flag == 0:\n",
        "            return span.text\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import itertools\n",
        "\n",
        "# def extract_name(text):\n",
        "  \n",
        "#   #Find names in Block letters\n",
        "#   names = re.findall('[A-Z]+\\.? ?[A-Z]+[\\n|,| |\\.]', text)\n",
        "\n",
        "#   #Find names in capitalized letters  ([A-Z][a-z]+?\\.?( ?[A-Z][a-z]+?){0,5} ?[A-Z][a-z]+?[\\n| |,]) \n",
        "#   names_2 = re.findall('([A-Z][a-z]+?\\.? ?( ?[A-Z][a-z]*?){0,5}\\.? ?[A-Z][a-z]*?[\\n| |,|.])', text)\n",
        "#   names_2 = list(itertools.chain(*names_2))\n",
        "\n",
        "#   #list of words to be avoided while parsing\n",
        "#   avoid_words = ['resume','résumé','cv', 'curriculum','marketing', 'curriculum vitae','vitae', 'curriculum vita',\n",
        "#                  'vita', 'name', 'pg', 'india', 'curriculam vitae', 'business development', 'cast', 'coc,','uae',\n",
        "#                  'address', 'email', 'email address', 'sales', 'u.p', 'product development', 'personal statement',\n",
        "#                  'full Name','street address', 'mobile', 'phone', 'number', 'phone number', 'mobile number', 'product',\n",
        "#                  'agarwal', 'inter', 'secondary', 'steels', 'element', 'engineering','system', 'school', 'operating',\n",
        "#                  'acknowledgement', 'assimilated', 'collaborated', 'collaboration','collaborations', 'india', 'isf,',\n",
        "#                  'professional summary', 'professional', 'title', 'job title', 'job' 'technological', 'high', 'college',\n",
        "#                  'top', 'device', 'launch', 'ams', 'crm', 'P Technological', 'project engineer', 'cgpa', 'gpa',\n",
        "#                  'personal profile', 'years', 'lv', 'career', 'career profile','lv', 'curriculum viate', 'civil',\n",
        "#                  'post applied', 'applied', 'post', 'for', 'electrical engineer', 'ps', 'district', 'ilets',\n",
        "#                  'career objective.', 'it', 'carrier objective', 'electrical project handling', 'mig,', 'hvac',\n",
        "#                  'mdu', 'linkedin', 'facebook', 'behance', 'youtube', 'github', 'in', 'portfolio','total experience',\n",
        "#                  'pbd','working','xcx','wwd','mba','dtdc','cf ril', 'fi', 'ef', 'dd', 'project management',\n",
        "#                  'engineer', 'apj', 'course university', 'university', 'ltd.', 'educational', 'n.y.', 's.s.',\n",
        "#                  'information technology', 'uk', 'usa', 'uae','pakistan','china','canada','saudia','arabia',\n",
        "#                  'educational background', 'details', 'personal details', 'clout', 'cloud', 'inditex', 'vy.', 'instrument',\n",
        "#                  'instrument super', 'bca', 'u.p.', 'qa', 'gis', 'gre', 'aicte', 'professional and', 'education background',\n",
        "#                  'tx', 'pvc', 'acadmic qualification', 'apply for merchandiser', 'education background','bechelor',\n",
        "#                  'beardsell pvt.', 'class', 'fi ef', 'uae,', 'of', 'b.s.', 'project', ''\n",
        "#                  'contributed', 'participated', 'participations', 'partnered', 'partnerships', 'volunteer work',\n",
        "#                  'volunteer', 'side activities', 'projects', 'education', 'experience', 'work', 'work experience',\n",
        "#                  'skills', 'interests', 'biography', 'bio', 'about me', 'about', 'info', 'contact', 'contact info',\n",
        "#                  'reference', 'reference will be established upon request', 'certificates', 'additional certificates',\n",
        "#                  'courses', 'student', 'online courses', 'short courses', 'languages', 'internships', 'organizations',\n",
        "#                  'organization', 'matriculation', 'intermediate', 'pre-engineering', 'bachelors', 'masters',\n",
        "#                  'bscs', 'bachelor of science', 'btech', 'btech', 'bachelor of technology', 'bs-cs,', 'sslc',\n",
        "#                  'bse', 'bachelor of commerce', 'bcom', 'b.com', 'information', 'personal information',\n",
        "#                  'info','achievements', 'personal projects', 'personal skills', 'summary', 'courses and certificates:',\n",
        "#                  'profile', 'hobbies & interests', 'hobbies and interests', 'hobbies', 'career objective',\n",
        "#                  'objective', 'other skills', 'academic', 'academics', 'academic qualification', 'references',\n",
        "#                  'personal', 'cnic', 'dob', 'date of birth', 'work history','computer skills', 'referenc',\n",
        "#                  'economics and finance', 'top skills', 'personal email', 'contact no', 'contact no.', \n",
        "#                  'cnic no', 'cnic no.', 'religion', 'domicile', 'a levels', 'o levels', 'working links',\n",
        "#                  'links', 'working experience', 'awards and achievements', 'awards', 'soft skills', \n",
        "#                  'volunteer experience', 'conferences and courses', 'conferences', 'educational qualification',\n",
        "#                  'educational qualifications', 'value addition', 'declaration', 'brief employment history',\n",
        "#                  'extra activities', 'extra', 'skills and responsibilities', 'duties and responsibilities',\n",
        "#                  'skills and abilities', 'area of expertise', 'technical skills', 'current address', \n",
        "#                  'permanent address', 'passport no', 'expiry date', 'career summary', 'email id', 'phone no',\n",
        "#                  'contact no', 'contact no.', 'phone no.', 'education qualification', 'python', 'js6', 'ansys'\n",
        "#                  ]\n",
        "\n",
        "#   #variable to limit iteration\n",
        "#   counter = 0\n",
        "#   #Checks whether an avoid word is present and skips over it\n",
        "#   for element in names:\n",
        "#     if counter==3:\n",
        "#       break\n",
        "#     if not element.lower().replace('\\n','').strip() in avoid_words:\n",
        "#       return element\n",
        "#     counter+=1\n",
        "  \n",
        "#   counter=0\n",
        "#   for element in names_2:\n",
        "#     if counter==4:\n",
        "#       break\n",
        "#     if not element.lower().replace('\\n','').strip() in avoid_words:\n",
        "#       return element\n",
        "#     counter+=1\n",
        "    \n",
        "  \n",
        "#   return ''"
      ],
      "metadata": {
        "id": "PRcllIbypBjl"
      },
      "id": "PRcllIbypBjl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize\n",
        "\n",
        "def extract_bigrams(text):\n",
        "  #Create Bigrams\n",
        "  tokens = word_tokenize(text)\n",
        "  bigrams = list(nltk.bigrams(tokens))\n",
        "  return bigrams\n",
        "\n",
        "def form_bigrams(bigrams):\n",
        "  #Forming possible combinations of first name and last name\n",
        "  listOfPossible = []\n",
        "  for word1,word2 in bigrams:\n",
        "    name = str(word1) + \" \" + str(word2)\n",
        "    listOfPossible.append(name)\n",
        "\n",
        "  return listOfPossible"
      ],
      "metadata": {
        "id": "OeELh0jWcHzZ"
      },
      "id": "OeELh0jWcHzZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fuzzywuzzy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xnsNFU2deD9",
        "outputId": "5b0611ab-f24c-44ea-ee11-3cb376f1c0b3"
      },
      "id": "8xnsNFU2deD9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.7/dist-packages (0.18.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fuzzywuzzy import process\n",
        "import pandas as pd\n",
        "\n",
        "def extract_name(possibleNames , emailID , content):\n",
        "\n",
        "  \"\"\"Remove matches with punctuations and avoided words to get best results\"\"\"\n",
        "  \n",
        "  ignore_words = [\"curriculum\" , \"vitae\" , \"vita\" , \"post\" , \"applied\" , \"for\" , \"address\" , \"resume\" , \"engineering\" , \"engineer\",\n",
        "                \"mechanical\" , \"address\" , \"mobile\" , \"contact\" , \"phone\" , \"temporary\" , \"street\" , \"resume\", \"computer\" ,\n",
        "                \"software\" , \"personal\" , \"information\" , \"name\" , \"date\" , \"box\" , \"work\" , \"professional\", \"near\" ,\n",
        "                \"objective\" , \"general\" , \"skills\" , \"skill\" , \"officer\" , \"administration\" , \"administrator\" , \"career\", \"position\",\n",
        "                \"technology\" , \"IT\", \"qualification\" , \"academic\", \"experience\", \"department\" , \"email\" , \"e-mail\" , \"curriculam\", \n",
        "                \"viate\" , \"education\" , \"location\"]\n",
        "\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "  \n",
        "  if emailID == None or emailID == '' or len(emailID) < 1:\n",
        "    return extract_name_using_Pronoun(content)\n",
        "\n",
        "  if (type(emailID) == list):\n",
        "    index = emailID[0].find('@')\n",
        "    extractedEmail = emailID[0][0:index]\n",
        "  else:\n",
        "    index = emailID.find('@')\n",
        "    extractedEmail = emailID[0:index]\n",
        "     \n",
        "  #Finding edit distance between two \n",
        "  \n",
        "  matches = process.extract(str(extractedEmail) , possibleNames , limit = len(possibleNames))\n",
        "  refinedList = []\n",
        "  \n",
        "  for match in matches:\n",
        "    foundwords = match[0].lower().split()\n",
        "    found = 0\n",
        "    for word in foundwords:\n",
        "      if word in ignore_words:\n",
        "        found = 1\n",
        "        break\n",
        "    if not(found):\n",
        "      token_words = word_tokenize(match[0])\n",
        "      flag = 0\n",
        "      for word in token_words:\n",
        "        if word in punctuations:\n",
        "          flag = 1 \n",
        "          break\n",
        "      if flag == 0:\n",
        "        refinedList.append(match)\n",
        "  print(refinedList)"
      ],
      "metadata": {
        "id": "xHvN87Oxcxuo"
      },
      "id": "xHvN87Oxcxuo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "3a62d346",
      "metadata": {
        "id": "3a62d346"
      },
      "source": [
        "# Extracting Phone Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7116e5a1",
      "metadata": {
        "id": "7116e5a1"
      },
      "outputs": [],
      "source": [
        "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG, resume_text)\n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        " \n",
        "        if resume_text.find(number) >= 0 and len(number) < 16:\n",
        "            return number\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23674a75",
      "metadata": {
        "id": "23674a75"
      },
      "source": [
        "# Extracting Email ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dc5c1d8",
      "metadata": {
        "id": "9dc5c1d8"
      },
      "outputs": [],
      "source": [
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "\n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Email ID"
      ],
      "metadata": {
        "id": "oD35jyRqCKTi"
      },
      "id": "oD35jyRqCKTi"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_emails(emailID):\n",
        "\n",
        "  # Identifying the string slicing for gmail\n",
        "  if type(emailID) == list:\n",
        "    emailNum = 0\n",
        "    for eml in emailID:\n",
        "        for i in range(len(eml)):\n",
        "          if eml[i] == '@':\n",
        "            index1 = i\n",
        "            break\n",
        "        for j in range(index1 , len(eml)):\n",
        "          if eml[j] == '.':\n",
        "            index2 = j\n",
        "            break\n",
        "        if eml[index1 + 1:index2] == 'qmail' or eml[index1 + 1:index2] == 'gqmail':\n",
        "          part1 = eml[0:index1 + 1]\n",
        "          part2 = eml[index1 + 1 : index2]\n",
        "          part3 = eml[index2:len(eml)]\n",
        "          eml = part1 + 'gmail' + part3\n",
        "        emailID[emailNum] = eml\n",
        "        emailNum =  emailNum + 1\n",
        "  else:\n",
        "    for i in range(len(emailID)):\n",
        "      if emailID[i] == '@':\n",
        "        index1 = i\n",
        "        break\n",
        "    for j in range(index1 , len(emailID)):\n",
        "      if emailID[j] == '.':\n",
        "        index2 = j\n",
        "        break\n",
        "    part1 = emailID[0:index1 + 1]\n",
        "    part2 = emailID[index1 + 1 : index2]\n",
        "    part3 = emailID[index2:len(emailID)]\n",
        "    emailID = part1 + 'gmail' + part3"
      ],
      "metadata": {
        "id": "XAQDY7usCJ7y"
      },
      "id": "XAQDY7usCJ7y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d296cedd",
      "metadata": {
        "id": "d296cedd"
      },
      "source": [
        "# Main Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f08f72b",
      "metadata": {
        "id": "2f08f72b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b737a338-8fb4-4e06-d681-4dee5e066a56"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['e-mail-kamilahmed502@gmail.com']\n",
            "[('8392850914 E-Mail-kamilahmed502', 90), ('in 2012', 49), ('Affiliated by', 46), ('Kamil Vill-', 45), ('Roorkee Affiliated', 42), ('Basic Knowledge', 40), ('PLC SCADA', 40), ('PLC SCADA', 40), ('a highly', 39), ('from UK', 39), ('in 2014', 39), ('from UK', 39), ('a job', 36), ('where |', 36), ('and knowledge', 36), ('Diploma in', 36), ('pursue a', 34), ('utilize my', 34), ('School Passed', 34), ('» Attended', 34), ('of Vocational', 34), ('can utilize', 32), ('Passed with', 32), ('PO- Salempur', 31), ('job in', 30), ('| can', 30), ('of IMS', 30), ('Knowledge of', 30), ('one month', 30), ('Zenus Infoted', 30), ('Vill- Safarpur', 29), ('Intermediate Passed', 29), ('knowledge efficiently', 28), ('2012 TECHNICAL', 28), ('years Diploma', 28), ('IMS Institute', 28), ('Attended one', 28), ('training in', 28), ('in P.T.C.U.L', 28), ('Automation PLC', 28), ('SCADA Course', 28), ('training from', 28), ('of Industrial', 28), ('Automation PLC', 28), ('SCADA Course', 28), ('of AutoCAD-2D/3D', 27), ('Salempur Rajputana', 26), ('and healthy', 26), ('environment where', 26), ('From SR', 26), ('Thermonix Institute', 26), ('From SR', 26), ('Thermonix Institute', 26), ('High School', 25), ('Three Months', 25), ('organizational growth', 24), ('three years', 24), ('Auto CAD-2D/3D', 24), ('Course From', 24), ('Course From', 24), ('challenging and', 23), ('with aggregate', 23), ('with aggregate', 23), ('with aggregate', 23), ('Attended Three', 23), ('Industrial Automation', 23), ('from P.T.C.U.L', 23), ('Industrial Automation', 23), ('UK Board', 22), ('Board in', 22), ('UK Board', 22), ('Board in', 22), ('Completed three', 22), ('from College', 22), ('month Vocational', 22), ('SR Thermonix', 22), ('SR Thermonix', 22), ('Rajputana ’', 21), ('in Electrical', 21), ('INDUSTRIAL EXPOSURE', 21), ('Vocational training', 21), ('Months Industrial', 21), ('Vocational training', 21), ('To pursue', 19), ('’ Roorkee-247667', 18), ('of 66', 18), ('of 73', 18), ('College of', 18), ('from Zenus', 18), ('highly rewarding', 17), ('in challenging', 17), ('aggregate of', 15), ('aggregate of', 15), ('aggregate of', 15), ('Institute of', 15), ('AutoCAD-2D/3D from', 15), ('by UBTER', 11), ('Certification of', 11), ('Certification of', 11), ('Certification of', 11)]\n",
            "[None, '8791917624', ['e-mail-kamilahmed502@gmail.com']]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import glob\n",
        "\n",
        "with open('output.csv', 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    for i in range(10):\n",
        "        IMG_PATH = '/content/drive/MyDrive/sampleresumes/' + str(i+21)\n",
        "        \n",
        "        text = \"\"\n",
        "        \n",
        "        # Img Pre Processing\n",
        "              \n",
        "        img = cv2.imread(IMG_PATH + '/page0.jpeg' )\n",
        "\n",
        "        img = ZoomImage(img , 3)\n",
        "        img = GrayScaleImage(img)\n",
        "        img = CropImage(img)\n",
        "        img = InvertImage(img)\n",
        "\n",
        "        cv2.imwrite(IMG_PATH + '/0.png', img)\n",
        "        img = cv2.imread(IMG_PATH + '/0.png')\n",
        "\n",
        "        # boundedImg = CreateBoundingBox(img)\n",
        "        # cv2.imwrite(IMG_PATH + '/a.png', boundedImg)\n",
        "        \n",
        "        # img = cv2.imread(IMG_PATH + '/0.png')\n",
        "\n",
        "        # NLP Part\n",
        "\n",
        "        text = ExtractText(img)\n",
        "        # print(text)      \n",
        "        # personName = extract_name(text.title())\n",
        "        contactNum = extract_phone_number(text.lower())\n",
        "        emailID = extract_emails(text.lower())\n",
        "        bigrams = extract_bigrams(text)\n",
        "        possibleNames = form_bigrams(bigrams)\n",
        "        process_emails(emailID)\n",
        "        print(emailID)\n",
        "        personName = extract_name(possibleNames , emailID , text)\n",
        "\n",
        "        row = []\n",
        "        row.append(personName)\n",
        "        row.append(contactNum)\n",
        "        row.append(emailID)\n",
        "        print(row)\n",
        "        print(\"\\n\")\n",
        "        writer.writerow(row)\n",
        "        break\n",
        "    f.close()\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "                 "
      ],
      "metadata": {
        "id": "Hf1bzBqHerRy"
      },
      "id": "Hf1bzBqHerRy",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Pytesseract.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}