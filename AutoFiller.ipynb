{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoFiller.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3c4234c"
      },
      "source": [
        "# Installing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract\n",
        "!apt-get install poppler-utils\n",
        "!sudo apt install tesseract-ocr\n",
        "!sudo apt install libtesseract-dev"
      ],
      "metadata": {
        "id": "UIK0r2jMNotK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Restart Runtime After Installation"
      ],
      "metadata": {
        "id": "-iCqt_hgBo5D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1881b845"
      },
      "source": [
        "# Importing Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4426083"
      },
      "outputs": [],
      "source": [
        "import cv2 \n",
        "import matplotlib.pyplot as plt\n",
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "import re\n",
        "try:\n",
        " from PIL import Image\n",
        "except ImportError:\n",
        " import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "050e86a4"
      },
      "source": [
        "# Downloading Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc6fcf7f",
        "outputId": "a6a4d112-8c22-45bf-a02b-bc4ab1770fd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-08-05 05:58:06.920188: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.4.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.4.0/en_core_web_sm-3.4.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.4.0) (3.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.23.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.8)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.21.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.11.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.64.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.9.1)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (21.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.6)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.6.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (8.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.3.0)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.4.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.2.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (4.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.7/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.4.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.9)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (5.2.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2022.6.15)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.7/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (0.7.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-sm==3.4.0) (2.0.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d19b21d1",
        "outputId": "1be66553-3765-412d-9bfd-9507b6852560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive"
      ],
      "metadata": {
        "id": "_bkGRDFGB4Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CIYUFICaPQ-",
        "outputId": "1d575f4b-d994-4a83-de97-6b2a4eec1ee1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "788d7abb"
      },
      "source": [
        "# Pre Processing Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27d0910b"
      },
      "outputs": [],
      "source": [
        "def ZoomImage(img, zoom_factor=2):\n",
        "    return cv2.resize(img, None, fx= zoom_factor, fy= zoom_factor, interpolation= cv2.INTER_LINEAR)\n",
        "\n",
        "def GrayScaleImage(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    gray = 255*(gray < 128).astype(np.uint8) \n",
        "    return gray\n",
        "\n",
        "def InvertImage(img):\n",
        "    return cv2.bitwise_not(img)\n",
        "\n",
        "def CropImage(img):\n",
        "    # Find all non-zero points (text)\n",
        "    coords = cv2.findNonZero(img) \n",
        "    # Find minimum spanning bounding box\n",
        "    x, y, w, h = cv2.boundingRect(coords) \n",
        "    # Crop the image - note we do this on the original image\n",
        "    img = img[y:y+h, x:x+w] \n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0583535"
      },
      "source": [
        "# Creating Bounding Box In Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c37bd914"
      },
      "outputs": [],
      "source": [
        "def CreateBoundingBox(img):\n",
        "    h, w, c = img.shape\n",
        "    boxes = pytesseract.image_to_boxes(img) \n",
        "    for b in boxes.splitlines():\n",
        "        b = b.split(' ')\n",
        "        img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff9ff256"
      },
      "source": [
        "# Extracting Text From Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "958fe4fd"
      },
      "outputs": [],
      "source": [
        "def ExtractText(img) : \n",
        "    custom_config = r'--oem 3 --psm 6'\n",
        "    text = pytesseract.image_to_string(img, config=custom_config)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffb2a5c6"
      },
      "source": [
        "# Extracting Name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre Processing For Name"
      ],
      "metadata": {
        "id": "8qqPGeKMxKgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def removing_extra(text):\n",
        "  new_sentence = \"\"\n",
        "  result = \"\"\n",
        "  token_sentence = sent_tokenize(text)\n",
        "  if \"applying for\" in token_sentence[0].lower() or \"applied for\" in token_sentence[0].lower() or \"post applied\" in token_sentence[0].lower():\n",
        "    sentences = token_sentence[0].split(\"\\n\")\n",
        "    for sent in sentences:\n",
        "      if \"applying for\" in sent.lower() or \"applied for\" in sent.lower():\n",
        "        continue\n",
        "      else:\n",
        "        new_sentence = new_sentence + sent + \"\\n\"\n",
        "\n",
        "    i = 0\n",
        "    for sentence in token_sentence:\n",
        "      if i == 0:\n",
        "        result = result + new_sentence + \"\\n\"\n",
        "      else:\n",
        "        result = result + sentence  + \"\\n\"\n",
        "      i += 1\n",
        "    return result \n",
        "  else:\n",
        "    return text"
      ],
      "metadata": {
        "id": "rgfz0pIaop7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc1267d1"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import words\n",
        "\n",
        "def extract_name(content):\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    matcher = Matcher(nlp.vocab)\n",
        "    ignore_words = [\"curriculum\" , \"vitae\" , \"vita\" , \"post\" , \"applied\" , \"for\" , \"address\" , \"resume\" , \"engineering\" , \"engineer\",\n",
        "                \"mechanical\" , \"address\" , \"mobile\" , \"contact\" , \"phone\" , \"temporary\" , \"street\" , \"resume\", \"computer\" ,\n",
        "                \"software\" , \"personal\" , \"information\" , \"name\" , \"date\" , \"box\" , \"work\" , \"professional\", \"near\" ,\n",
        "                \"objective\" , \"general\" , \"skills\" , \"skill\" , \"officer\" , \"administration\" , \"administrator\" , \"career\", \"position\",\n",
        "                \"technology\" , \"IT\", \"qualification\" , \"academic\", \"experience\", \"department\" , \"email\" , \"e-mail\" , \"curriculam\", \n",
        "                \"viate\" , \"education\" , \"location\" , \"hr\" ]\n",
        "\n",
        "    new_content = removing_extra(content)\n",
        "    \n",
        "    nlp_text = nlp(new_content)\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>/?@#$%^&*_~'''\n",
        "    pattern = [{'POS': 'PROPN'}, {'POS': 'PROPN'}]\n",
        "    \n",
        "    matcher.add('NAME', [pattern])\n",
        "    \n",
        "    matches = matcher(nlp_text)\n",
        "\n",
        "    for match_id, start, end in matches:\n",
        "        span = nlp_text[start:end]\n",
        "        foundwords = span.text.lower().split()\n",
        "        found = 0\n",
        "        for word in foundwords:\n",
        "          if word in ignore_words:\n",
        "            found = 1\n",
        "            break\n",
        "        if not(found):\n",
        "          token_words = word_tokenize(span.text)\n",
        "          flag = 0\n",
        "          for word in token_words:\n",
        "            if word in punctuations:\n",
        "              flag = 1 \n",
        "              break\n",
        "          if flag == 0:\n",
        "            return span.text\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a62d346"
      },
      "source": [
        "# Extracting Phone Number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7116e5a1"
      },
      "outputs": [],
      "source": [
        "PHONE_REG = re.compile(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]')\n",
        "def extract_phone_number(resume_text):\n",
        "    phone = re.findall(PHONE_REG, resume_text)\n",
        "    if phone:\n",
        "        number = ''.join(phone[0])\n",
        " \n",
        "        if resume_text.find(number) >= 0 and len(number) < 16:\n",
        "            return number\n",
        "    return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23674a75"
      },
      "source": [
        "# Extracting Email ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dc5c1d8"
      },
      "outputs": [],
      "source": [
        "EMAIL_REG = re.compile(r'[a-z0-9\\.\\-+_]+@[a-z0-9\\.\\-+_]+\\.[a-z]+')\n",
        "\n",
        "def extract_emails(resume_text):\n",
        "    return re.findall(EMAIL_REG, resume_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processing Email ID"
      ],
      "metadata": {
        "id": "oD35jyRqCKTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_emails(emailID):\n",
        "\n",
        "  # Identifying the string slicing for gmail\n",
        "  if type(emailID) == list:\n",
        "    emailNum = 0\n",
        "    for eml in emailID:\n",
        "        for i in range(len(eml)):\n",
        "          if eml[i] == '@':\n",
        "            index1 = i\n",
        "            break\n",
        "        for j in range(index1 , len(eml)):\n",
        "          if eml[j] == '.':\n",
        "            index2 = j\n",
        "            break\n",
        "        if eml[index1 + 1:index2] == 'qmail' or eml[index1 + 1:index2] == 'gqmail':\n",
        "          part1 = eml[0:index1 + 1]\n",
        "          part2 = eml[index1 + 1 : index2]\n",
        "          part3 = eml[index2:len(eml)]\n",
        "          eml = part1 + 'gmail' + part3\n",
        "        emailID[emailNum] = eml\n",
        "        emailNum =  emailNum + 1\n",
        "  else:\n",
        "    for i in range(len(emailID)):\n",
        "      if emailID[i] == '@':\n",
        "        index1 = i\n",
        "        break\n",
        "    for j in range(index1 , len(emailID)):\n",
        "      if emailID[j] == '.':\n",
        "        index2 = j\n",
        "        break\n",
        "    part1 = emailID[0:index1 + 1]\n",
        "    part2 = emailID[index1 + 1 : index2]\n",
        "    part3 = emailID[index2:len(emailID)]\n",
        "    emailID = part1 + 'gmail' + part3"
      ],
      "metadata": {
        "id": "XAQDY7usCJ7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d296cedd"
      },
      "source": [
        "# Main Program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f08f72b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27c2f83b-46bd-4ed6-95cd-0b106ef026b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mubasheer Ahmed', '+919182834870', ['mubasheerkhan@gmail.com']]\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import glob\n",
        "\n",
        "with open('output.csv', 'w', encoding='UTF8') as f:\n",
        "    writer = csv.writer(f)\n",
        "\n",
        "    for i in range(50):\n",
        "        IMG_PATH = '/content/drive/MyDrive/sampleresumes/' + str(i+1)\n",
        "        \n",
        "        text = \"\"\n",
        "        \n",
        "        # Img Pre Processing\n",
        "              \n",
        "        img = cv2.imread(IMG_PATH + '/page0.jpeg' )\n",
        "\n",
        "        img = ZoomImage(img , 3)\n",
        "        img = GrayScaleImage(img)\n",
        "        img = CropImage(img)\n",
        "        img = InvertImage(img)\n",
        "\n",
        "        cv2.imwrite(IMG_PATH + '/0.png', img)\n",
        "        img = cv2.imread(IMG_PATH + '/0.png')\n",
        "\n",
        "        # NLP Part\n",
        "\n",
        "        text = ExtractText(img)\n",
        "        personName = extract_name(text.title())\n",
        "        contactNum = extract_phone_number(text.lower())\n",
        "        emailID = extract_emails(text.lower())\n",
        "        process_emails(emailID)\n",
        "       \n",
        "        row = []\n",
        "        row.append(personName)\n",
        "        row.append(contactNum)\n",
        "        row.append(emailID)\n",
        "        print(row)\n",
        "        writer.writerow(row)\n",
        "        break\n",
        "    f.close()"
      ]
    }
  ]
}